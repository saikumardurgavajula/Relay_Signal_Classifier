{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041e1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc0533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"improved_preprocessed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2983e0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4966 entries, 0 to 4965\n",
      "Columns: 120 entries, R1-PA1:VH to marker\n",
      "dtypes: float64(112), int64(7), object(1)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93dd4055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1-PA1:VH</th>\n",
       "      <th>R1-PM1:V</th>\n",
       "      <th>R1-PA2:VH</th>\n",
       "      <th>R1-PM2:V</th>\n",
       "      <th>R1-PA3:VH</th>\n",
       "      <th>R1-PM3:V</th>\n",
       "      <th>R1-PA4:IH</th>\n",
       "      <th>R1-PM4:I</th>\n",
       "      <th>R1-PA5:IH</th>\n",
       "      <th>R1-PM5:I</th>\n",
       "      <th>...</th>\n",
       "      <th>R4-PM12:I</th>\n",
       "      <th>R4:F</th>\n",
       "      <th>R4:DF</th>\n",
       "      <th>R4-PA:Z</th>\n",
       "      <th>R4-PA:ZH</th>\n",
       "      <th>R4:S</th>\n",
       "      <th>relay1_log</th>\n",
       "      <th>relay2_log</th>\n",
       "      <th>relay3_log</th>\n",
       "      <th>relay4_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.966000e+03</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4.966000e+03</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.000000</td>\n",
       "      <td>4966.0</td>\n",
       "      <td>4966.0</td>\n",
       "      <td>4966.0</td>\n",
       "      <td>4966.0</td>\n",
       "      <td>4966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-17.925492</td>\n",
       "      <td>131642.877159</td>\n",
       "      <td>8.610555</td>\n",
       "      <td>131381.627418</td>\n",
       "      <td>1.681621</td>\n",
       "      <td>131711.442402</td>\n",
       "      <td>-18.174249</td>\n",
       "      <td>403.779397</td>\n",
       "      <td>10.930328</td>\n",
       "      <td>403.804157</td>\n",
       "      <td>...</td>\n",
       "      <td>7.404327e+00</td>\n",
       "      <td>59.999358</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>10.330778</td>\n",
       "      <td>0.014666</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>98.099812</td>\n",
       "      <td>1413.577106</td>\n",
       "      <td>115.044643</td>\n",
       "      <td>1416.152391</td>\n",
       "      <td>96.408966</td>\n",
       "      <td>1422.205311</td>\n",
       "      <td>97.374545</td>\n",
       "      <td>117.020229</td>\n",
       "      <td>111.679895</td>\n",
       "      <td>107.440501</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199162e-13</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>2.637045e-16</td>\n",
       "      <td>3.345532</td>\n",
       "      <td>0.097103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-179.988962</td>\n",
       "      <td>127622.944500</td>\n",
       "      <td>-179.994691</td>\n",
       "      <td>127322.064900</td>\n",
       "      <td>-179.960314</td>\n",
       "      <td>127622.944400</td>\n",
       "      <td>-179.988962</td>\n",
       "      <td>3.662200</td>\n",
       "      <td>-179.736860</td>\n",
       "      <td>7.507510</td>\n",
       "      <td>...</td>\n",
       "      <td>7.404327e+00</td>\n",
       "      <td>59.996000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.267951</td>\n",
       "      <td>-0.283431</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-97.404258</td>\n",
       "      <td>131007.835800</td>\n",
       "      <td>-99.085889</td>\n",
       "      <td>130706.956500</td>\n",
       "      <td>-77.405166</td>\n",
       "      <td>131064.250625</td>\n",
       "      <td>-97.626279</td>\n",
       "      <td>331.474877</td>\n",
       "      <td>-90.269501</td>\n",
       "      <td>336.006850</td>\n",
       "      <td>...</td>\n",
       "      <td>7.404327e+00</td>\n",
       "      <td>59.999000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>8.257677</td>\n",
       "      <td>-0.025894</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-35.864293</td>\n",
       "      <td>131634.667500</td>\n",
       "      <td>17.077007</td>\n",
       "      <td>131333.788300</td>\n",
       "      <td>14.080438</td>\n",
       "      <td>131684.814000</td>\n",
       "      <td>-33.369062</td>\n",
       "      <td>393.869610</td>\n",
       "      <td>10.930328</td>\n",
       "      <td>395.517600</td>\n",
       "      <td>...</td>\n",
       "      <td>7.404327e+00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>9.733030</td>\n",
       "      <td>0.021392</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71.277382</td>\n",
       "      <td>132136.132900</td>\n",
       "      <td>116.783123</td>\n",
       "      <td>131835.253700</td>\n",
       "      <td>77.995312</td>\n",
       "      <td>132211.352700</td>\n",
       "      <td>67.545994</td>\n",
       "      <td>464.321183</td>\n",
       "      <td>115.522615</td>\n",
       "      <td>469.127820</td>\n",
       "      <td>...</td>\n",
       "      <td>7.404327e+00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>11.885319</td>\n",
       "      <td>0.059952</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>179.994691</td>\n",
       "      <td>135521.024200</td>\n",
       "      <td>179.971773</td>\n",
       "      <td>135220.145300</td>\n",
       "      <td>179.966044</td>\n",
       "      <td>135652.658925</td>\n",
       "      <td>179.925936</td>\n",
       "      <td>862.860098</td>\n",
       "      <td>179.988962</td>\n",
       "      <td>868.490730</td>\n",
       "      <td>...</td>\n",
       "      <td>7.404327e+00</td>\n",
       "      <td>60.003000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>22.768245</td>\n",
       "      <td>0.317489</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         R1-PA1:VH       R1-PM1:V    R1-PA2:VH       R1-PM2:V    R1-PA3:VH  \\\n",
       "count  4966.000000    4966.000000  4966.000000    4966.000000  4966.000000   \n",
       "mean    -17.925492  131642.877159     8.610555  131381.627418     1.681621   \n",
       "std      98.099812    1413.577106   115.044643    1416.152391    96.408966   \n",
       "min    -179.988962  127622.944500  -179.994691  127322.064900  -179.960314   \n",
       "25%     -97.404258  131007.835800   -99.085889  130706.956500   -77.405166   \n",
       "50%     -35.864293  131634.667500    17.077007  131333.788300    14.080438   \n",
       "75%      71.277382  132136.132900   116.783123  131835.253700    77.995312   \n",
       "max     179.994691  135521.024200   179.971773  135220.145300   179.966044   \n",
       "\n",
       "            R1-PM3:V    R1-PA4:IH     R1-PM4:I    R1-PA5:IH     R1-PM5:I  ...  \\\n",
       "count    4966.000000  4966.000000  4966.000000  4966.000000  4966.000000  ...   \n",
       "mean   131711.442402   -18.174249   403.779397    10.930328   403.804157  ...   \n",
       "std      1422.205311    97.374545   117.020229   111.679895   107.440501  ...   \n",
       "min    127622.944400  -179.988962     3.662200  -179.736860     7.507510  ...   \n",
       "25%    131064.250625   -97.626279   331.474877   -90.269501   336.006850  ...   \n",
       "50%    131684.814000   -33.369062   393.869610    10.930328   395.517600  ...   \n",
       "75%    132211.352700    67.545994   464.321183   115.522615   469.127820  ...   \n",
       "max    135652.658925   179.925936   862.860098   179.988962   868.490730  ...   \n",
       "\n",
       "          R4-PM12:I         R4:F         R4:DF      R4-PA:Z     R4-PA:ZH  \\\n",
       "count  4.966000e+03  4966.000000  4.966000e+03  4966.000000  4966.000000   \n",
       "mean   7.404327e+00    59.999358  1.000000e-02    10.330778     0.014666   \n",
       "std    1.199162e-13     0.001680  2.637045e-16     3.345532     0.097103   \n",
       "min    7.404327e+00    59.996000  1.000000e-02     0.267951    -0.283431   \n",
       "25%    7.404327e+00    59.999000  1.000000e-02     8.257677    -0.025894   \n",
       "50%    7.404327e+00    60.000000  1.000000e-02     9.733030     0.021392   \n",
       "75%    7.404327e+00    60.000000  1.000000e-02    11.885319     0.059952   \n",
       "max    7.404327e+00    60.003000  1.000000e-02    22.768245     0.317489   \n",
       "\n",
       "         R4:S  relay1_log  relay2_log  relay3_log  relay4_log  \n",
       "count  4966.0      4966.0      4966.0      4966.0      4966.0  \n",
       "mean   2048.0         1.0         1.0         1.0         1.0  \n",
       "std       0.0         0.0         0.0         0.0         0.0  \n",
       "min    2048.0         1.0         1.0         1.0         1.0  \n",
       "25%    2048.0         1.0         1.0         1.0         1.0  \n",
       "50%    2048.0         1.0         1.0         1.0         1.0  \n",
       "75%    2048.0         1.0         1.0         1.0         1.0  \n",
       "max    2048.0         1.0         1.0         1.0         1.0  \n",
       "\n",
       "[8 rows x 119 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099ef471",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[\"R1-PA1:VH\", \"R1-PM1:V\", \"R1-PA2:VH\", \"R1-PM2:V\", \"R1-PA3:VH\", \"R1-PM3:V\", \n",
    "        \"R1-PA4:IH\", \"R1-PM4:I\", \"R1-PA5:IH\", \"R1-PM5:I\", \"R1-PA6:IH\", \"R1-PM6:I\", \n",
    "        \"R1-PA7:VH\", \"R1-PM7:V\", \"R1-PA8:VH\", \"R1-PM8:V\", \"R1-PA9:VH\", \"R1-PM9:V\", \n",
    "        \"R1-PA10:IH\", \"R1-PM10:I\", \"R1-PA11:IH\", \"R1-PM11:I\", \"R1-PA12:IH\", \"R1-PM12:I\", \n",
    "        \"R1:F\", \"R1:DF\", \"R1-PA:Z\", \"R1-PA:ZH\", \"R1:S\"]]\n",
    "\n",
    "y = df[[\"marker\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2433edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1-PA1:VH</th>\n",
       "      <th>R1-PM1:V</th>\n",
       "      <th>R1-PA2:VH</th>\n",
       "      <th>R1-PM2:V</th>\n",
       "      <th>R1-PA3:VH</th>\n",
       "      <th>R1-PM3:V</th>\n",
       "      <th>R1-PA4:IH</th>\n",
       "      <th>R1-PM4:I</th>\n",
       "      <th>R1-PA5:IH</th>\n",
       "      <th>R1-PM5:I</th>\n",
       "      <th>...</th>\n",
       "      <th>R1-PM10:I</th>\n",
       "      <th>R1-PA11:IH</th>\n",
       "      <th>R1-PM11:I</th>\n",
       "      <th>R1-PA12:IH</th>\n",
       "      <th>R1-PM12:I</th>\n",
       "      <th>R1:F</th>\n",
       "      <th>R1:DF</th>\n",
       "      <th>R1-PA:Z</th>\n",
       "      <th>R1-PA:ZH</th>\n",
       "      <th>R1:S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.399324</td>\n",
       "      <td>127673.0908</td>\n",
       "      <td>-49.572308</td>\n",
       "      <td>127648.0176</td>\n",
       "      <td>-169.578319</td>\n",
       "      <td>127723.2374</td>\n",
       "      <td>65.689611</td>\n",
       "      <td>605.91099</td>\n",
       "      <td>-57.003571</td>\n",
       "      <td>626.78553</td>\n",
       "      <td>...</td>\n",
       "      <td>611.58740</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>-10.446010</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>59.999</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.391383</td>\n",
       "      <td>0.076290</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.688102</td>\n",
       "      <td>130280.7109</td>\n",
       "      <td>-46.300719</td>\n",
       "      <td>130255.6377</td>\n",
       "      <td>-166.278082</td>\n",
       "      <td>130355.9307</td>\n",
       "      <td>71.831719</td>\n",
       "      <td>483.59351</td>\n",
       "      <td>-50.947407</td>\n",
       "      <td>500.98896</td>\n",
       "      <td>...</td>\n",
       "      <td>488.35437</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>-10.446010</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>60.003</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.185463</td>\n",
       "      <td>0.024924</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.733939</td>\n",
       "      <td>130305.7842</td>\n",
       "      <td>-46.254883</td>\n",
       "      <td>130280.7109</td>\n",
       "      <td>-166.232245</td>\n",
       "      <td>130381.0040</td>\n",
       "      <td>71.808800</td>\n",
       "      <td>483.59351</td>\n",
       "      <td>-50.913030</td>\n",
       "      <td>500.98896</td>\n",
       "      <td>...</td>\n",
       "      <td>488.35437</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>-10.446010</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>60.003</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.190006</td>\n",
       "      <td>0.027904</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.083443</td>\n",
       "      <td>130581.5902</td>\n",
       "      <td>-45.899649</td>\n",
       "      <td>130556.5169</td>\n",
       "      <td>-165.882741</td>\n",
       "      <td>130656.8100</td>\n",
       "      <td>72.152575</td>\n",
       "      <td>482.86107</td>\n",
       "      <td>-50.437475</td>\n",
       "      <td>499.15786</td>\n",
       "      <td>...</td>\n",
       "      <td>487.62193</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>-10.446010</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>60.003</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.171532</td>\n",
       "      <td>0.025617</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.553268</td>\n",
       "      <td>131083.0556</td>\n",
       "      <td>-45.424094</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>-165.424375</td>\n",
       "      <td>131158.2754</td>\n",
       "      <td>72.118198</td>\n",
       "      <td>484.50906</td>\n",
       "      <td>-50.013486</td>\n",
       "      <td>497.69298</td>\n",
       "      <td>...</td>\n",
       "      <td>488.90370</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>-10.446010</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>60.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.079496</td>\n",
       "      <td>0.032941</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>28.229631</td>\n",
       "      <td>130882.4694</td>\n",
       "      <td>-91.730543</td>\n",
       "      <td>130882.4694</td>\n",
       "      <td>148.264289</td>\n",
       "      <td>130957.6892</td>\n",
       "      <td>25.553918</td>\n",
       "      <td>459.42299</td>\n",
       "      <td>-95.683952</td>\n",
       "      <td>466.93050</td>\n",
       "      <td>...</td>\n",
       "      <td>462.16964</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>-10.446010</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>59.999</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.310113</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>28.195253</td>\n",
       "      <td>130957.6892</td>\n",
       "      <td>-91.770650</td>\n",
       "      <td>130932.6159</td>\n",
       "      <td>148.224182</td>\n",
       "      <td>131032.9090</td>\n",
       "      <td>25.267439</td>\n",
       "      <td>460.70476</td>\n",
       "      <td>-95.752707</td>\n",
       "      <td>467.66294</td>\n",
       "      <td>...</td>\n",
       "      <td>463.45141</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>-10.446010</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.256475</td>\n",
       "      <td>0.044691</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>28.000447</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>-91.971185</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>148.035105</td>\n",
       "      <td>131133.2021</td>\n",
       "      <td>24.316329</td>\n",
       "      <td>464.36696</td>\n",
       "      <td>-96.251180</td>\n",
       "      <td>468.94471</td>\n",
       "      <td>...</td>\n",
       "      <td>466.19806</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>21.418347</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.156751</td>\n",
       "      <td>0.062308</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>27.971800</td>\n",
       "      <td>131083.0556</td>\n",
       "      <td>-91.994104</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>148.006458</td>\n",
       "      <td>131133.2021</td>\n",
       "      <td>24.259033</td>\n",
       "      <td>464.18385</td>\n",
       "      <td>-96.314205</td>\n",
       "      <td>469.12782</td>\n",
       "      <td>...</td>\n",
       "      <td>466.19806</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>21.418347</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.167257</td>\n",
       "      <td>0.062861</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>27.931693</td>\n",
       "      <td>131083.0556</td>\n",
       "      <td>-92.034211</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>147.966351</td>\n",
       "      <td>131133.2021</td>\n",
       "      <td>24.241844</td>\n",
       "      <td>464.00074</td>\n",
       "      <td>-96.342853</td>\n",
       "      <td>469.12782</td>\n",
       "      <td>...</td>\n",
       "      <td>466.19806</td>\n",
       "      <td>0.45324</td>\n",
       "      <td>7.69062</td>\n",
       "      <td>-10.446010</td>\n",
       "      <td>7.50751</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.174156</td>\n",
       "      <td>0.061432</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4966 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      R1-PA1:VH     R1-PM1:V  R1-PA2:VH     R1-PM2:V   R1-PA3:VH     R1-PM3:V  \\\n",
       "0     70.399324  127673.0908 -49.572308  127648.0176 -169.578319  127723.2374   \n",
       "1     73.688102  130280.7109 -46.300719  130255.6377 -166.278082  130355.9307   \n",
       "2     73.733939  130305.7842 -46.254883  130280.7109 -166.232245  130381.0040   \n",
       "3     74.083443  130581.5902 -45.899649  130556.5169 -165.882741  130656.8100   \n",
       "4     74.553268  131083.0556 -45.424094  131057.9823 -165.424375  131158.2754   \n",
       "...         ...          ...        ...          ...         ...          ...   \n",
       "4961  28.229631  130882.4694 -91.730543  130882.4694  148.264289  130957.6892   \n",
       "4962  28.195253  130957.6892 -91.770650  130932.6159  148.224182  131032.9090   \n",
       "4963  28.000447  131057.9823 -91.971185  131057.9823  148.035105  131133.2021   \n",
       "4964  27.971800  131083.0556 -91.994104  131057.9823  148.006458  131133.2021   \n",
       "4965  27.931693  131083.0556 -92.034211  131057.9823  147.966351  131133.2021   \n",
       "\n",
       "      R1-PA4:IH   R1-PM4:I  R1-PA5:IH   R1-PM5:I  ...  R1-PM10:I  R1-PA11:IH  \\\n",
       "0     65.689611  605.91099 -57.003571  626.78553  ...  611.58740     0.45324   \n",
       "1     71.831719  483.59351 -50.947407  500.98896  ...  488.35437     0.45324   \n",
       "2     71.808800  483.59351 -50.913030  500.98896  ...  488.35437     0.45324   \n",
       "3     72.152575  482.86107 -50.437475  499.15786  ...  487.62193     0.45324   \n",
       "4     72.118198  484.50906 -50.013486  497.69298  ...  488.90370     0.45324   \n",
       "...         ...        ...        ...        ...  ...        ...         ...   \n",
       "4961  25.553918  459.42299 -95.683952  466.93050  ...  462.16964     0.45324   \n",
       "4962  25.267439  460.70476 -95.752707  467.66294  ...  463.45141     0.45324   \n",
       "4963  24.316329  464.36696 -96.251180  468.94471  ...  466.19806     0.45324   \n",
       "4964  24.259033  464.18385 -96.314205  469.12782  ...  466.19806     0.45324   \n",
       "4965  24.241844  464.00074 -96.342853  469.12782  ...  466.19806     0.45324   \n",
       "\n",
       "      R1-PM11:I  R1-PA12:IH  R1-PM12:I    R1:F  R1:DF   R1-PA:Z  R1-PA:ZH  \\\n",
       "0       7.69062  -10.446010    7.50751  59.999   0.01  6.391383  0.076290   \n",
       "1       7.69062  -10.446010    7.50751  60.003   0.01  8.185463  0.024924   \n",
       "2       7.69062  -10.446010    7.50751  60.003   0.01  8.190006  0.027904   \n",
       "3       7.69062  -10.446010    7.50751  60.003   0.01  8.171532  0.025617   \n",
       "4       7.69062  -10.446010    7.50751  60.001   0.01  8.079496  0.032941   \n",
       "...         ...         ...        ...     ...    ...       ...       ...   \n",
       "4961    7.69062  -10.446010    7.50751  59.999   0.01  8.310113  0.039983   \n",
       "4962    7.69062  -10.446010    7.50751  60.000   0.01  8.256475  0.044691   \n",
       "4963    7.69062   21.418347    7.50751  60.000   0.01  8.156751  0.062308   \n",
       "4964    7.69062   21.418347    7.50751  60.000   0.01  8.167257  0.062861   \n",
       "4965    7.69062  -10.446010    7.50751  60.000   0.01  8.174156  0.061432   \n",
       "\n",
       "      R1:S  \n",
       "0     2048  \n",
       "1     2048  \n",
       "2     2048  \n",
       "3     2048  \n",
       "4     2048  \n",
       "...    ...  \n",
       "4961  2048  \n",
       "4962  2048  \n",
       "4963  2048  \n",
       "4964  2048  \n",
       "4965  2048  \n",
       "\n",
       "[4966 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32f99fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\durga\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoded_data = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7819bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,encoded_data,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9985c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3724, 29), (1242, 29))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f03ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "x_train_std = scaler.fit_transform(x_train)\n",
    "x_test_std=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c68f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\durga\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\durga\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n",
      "C:\\Users\\durga\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\durga\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#%% Apply SMOTE to oversample the minority class for both train and test sets\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(x_train_std, y_train)\n",
    "X_resampled_test, y_resampled_test = smote.fit_resample(x_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d2d507",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19124\\615524014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_resampled_test)\n",
    "print(classification_report(y_resampled_test, y_pred))\n",
    "print(confusion_matrix(y_resampled_test, y_pred))\n",
    "# Compute confusion matrix using the true and predicted labels\n",
    "cm = confusion_matrix(y_resampled_test,y_pred)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"ACCURACY SCORE\",accuracy_score(y_resampled_test,y_pred))\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - Random Forest Classifier after SMOTE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1166d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\durga\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [14:25:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for xg boost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       941\n",
      "           1       0.96      0.91      0.93       941\n",
      "\n",
      "    accuracy                           0.93      1882\n",
      "   macro avg       0.93      0.93      0.93      1882\n",
      "weighted avg       0.93      0.93      0.93      1882\n",
      "\n",
      "Confusion Matrix for xg boost:\n",
      " [[902  39]\n",
      " [ 88 853]]\n",
      "ACCURACY SCORE 0.9325185972369819\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#xg boost(xgbc)\n",
    "from xgboost import XGBClassifier\n",
    "xgbc = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgbc.fit(X_resampled, y_resampled)\n",
    "y_pred = xgbc.predict(X_resampled_test)\n",
    "print(\"Classification Report for xg boost:\\n\", classification_report(y_resampled_test, y_pred))\n",
    "print(\"Confusion Matrix for xg boost:\\n\", confusion_matrix(y_resampled_test, y_pred))\n",
    "# Compute confusion matrix using the true and predicted labels\n",
    "cm = confusion_matrix(y_resampled_test,y_pred)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"ACCURACY SCORE\",accuracy_score(y_resampled_test,y_pred))\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - XG Boost after SMOTE')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "y_resampled_enc = le.fit_transform(y_resampled)  # Convert training labels\n",
    "y_resampled_test_enc = le.transform(y_resampled_test)  # Convert test labels\n",
    "\n",
    "#%% Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix'):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "#%% Train classifiers and plot confusion matrices\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    print(f\"\\nTraining {label}...\")\n",
    "    clf.fit(X_resampled, y_resampled_enc)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = clf.predict(X_resampled_test)  # ✅ Fix applied\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_resampled_test_enc, y_pred)\n",
    "    print(f\"Confusion Matrix for {label}:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Plot heatmap of confusion matrix\n",
    "    plot_confusion_matrix(cm, classes=np.unique(y_resampled_test_enc), title=f'Confusion Matrix: {label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "y_resampled_enc = le.fit_transform(y_resampled)  # Encode training labels\n",
    "y_resampled_test_enc = le.transform(y_resampled_test)  # Encode test labels\n",
    "\n",
    "# Define colors and line styles for plots\n",
    "colors = [\"black\", \"orange\", \"blue\", \"green\", \"pink\", \"red\", \"brown\", \"magenta\"]\n",
    "linestyles = [\":\", \"--\", \"-.\", \"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "\n",
    "# Plot ROC curves for all classifiers\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context('paper', font_scale=1.5)\n",
    "\n",
    "for clf, label, clr, ls in zip(all_clf, clf_labels, colors, linestyles):\n",
    "    clf.fit(X_resampled, y_resampled_enc)  # Train model\n",
    "    y_pred_proba = clf.predict_proba(X_resampled_test)[:, 1]  # Predict probabilities\n",
    "    \n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_resampled_test_enc, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, color=clr, linestyle=ls, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot diagonal random guess line\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', linewidth=2)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('AUC-ROC Curves for All Models')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mapping of encoded values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "print(\"Label Encoding Mapping:\")\n",
    "for original_label, encoded_value in label_mapping.items():\n",
    "    print(f\"'{original_label}' -> {encoded_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11698200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model, Label Encoder, and Scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Train/Test Split\n",
    "# Ensure you're using the correct dataset names\n",
    "X_train = X_resampled  \n",
    "y_train = y_resampled  \n",
    "X_test = X_resampled_test  \n",
    "y_test = y_resampled_test  \n",
    "\n",
    "# Encode labels (if categorical)\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()  # Change to XGBRegressor() if regression\n",
    "xgb_model.fit(X_train_scaled, y_train_enc)\n",
    "\n",
    "# Save Model, Label Encoder, and Scaler\n",
    "with open(\"xgboost.pkl\", \"wb\") as file:\n",
    "    pickle.dump(xgb_model, file)\n",
    "\n",
    "with open(\"label_encoder.pkl\", \"wb\") as file:\n",
    "    pickle.dump(le, file)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "print(\"✅ Model, Label Encoder, and Scaler saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(\"X_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
